{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6868189,"sourceType":"datasetVersion","datasetId":3937441}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">LLM - Detect AI Generated Text</p>","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Introduction ğŸ“</h1>\nWelcome to a competition where we need to determine whether an essay was authored by a student or an LLM. Within this notebook, my initial focus will involve delving into the dataset. I'll employ the magic of plotly for a comprehensive exploration of the data, followed by subsequent stages of data processing and modeling.","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Dataset Info ğŸ“ˆ</h1>\n<h2>Training Data</h2>\n<b>{test|train}_essays.csv</b><br>\n\n* ```id``` - A unique identifier for each essay.\n* ```prompt_id``` - Identifies the prompt the essay was written in response to.\n* ```text``` - The essay text itself.\n* ```generated``` - Whether the essay was written by a student (0) or generated by an LLM (1). This field is the target and is not present in test_essays.csv.\n\n<b>train_prompts.csv - Essays were written in response to information in these fields.</b><br>\n\n* ```prompt_id``` - A unique identifier for each prompt.\n* ```prompt_name``` - The title of the prompt.\n* ```instructions``` - The instructions given to students.\n* ```source_text``` - The text of the article(s) the essays were written in response to, in Markdown format.","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>Evaluation Metric ğŸ“</h1>\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">TABLE OF CONTENTS</p>\n<ul style=\"list-style-type:square\">\n    <li><a href=\"#1\">Importing Libraries</a></li>\n    <li><a href=\"#2\">Reading the data</a></li>\n    <li><a href=\"#3\">Exploratory Data Analysis</a></li>\n    <li><a href=\"#4\">Create Folds</a></li>\n    <li><a href=\"#5\">Dataset Class</a></li>\n    <li><a href=\"#6\">Baseline Model</a></li>\n    <li><a href=\"#7\">Utility Functions</a></li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">IMPORTING LIBRARIES</p>","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport wandb\nimport random\nimport requests\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom PIL import Image\nimport plotly.io as pio\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom kaggle_secrets import UserSecretsClient\n\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel, get_linear_schedule_with_warmup\n\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Set global template and layout colors\npio.templates.default = \"plotly_dark\"\npio.templates[pio.templates.default].layout['paper_bgcolor'] = '#1F1F1F'\npio.templates[pio.templates.default].layout['plot_bgcolor'] = '#1F1F1F'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T18:36:02.830956Z","iopub.execute_input":"2023-12-24T18:36:02.831956Z","iopub.status.idle":"2023-12-24T18:36:02.862089Z","shell.execute_reply.started":"2023-12-24T18:36:02.83192Z","shell.execute_reply":"2023-12-24T18:36:02.861056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    seed=300\n    num_fold = 3\n    model = 'roberta-base'\n    max_len = 512\n    train_batch_size = 16\n    valid_batch_size = 16\n    epochs = 2\n    learning_rate = 1e-5\n    scheduler = 'linear'\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    tokenizer = AutoTokenizer.from_pretrained(model)\n    \nCONFIG.tokenizer.save_pretrained('./tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:03.001833Z","iopub.execute_input":"2023-12-24T18:36:03.002126Z","iopub.status.idle":"2023-12-24T18:36:03.460009Z","shell.execute_reply.started":"2023-12-24T18:36:03.0021Z","shell.execute_reply":"2023-12-24T18:36:03.458997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(CONFIG.seed)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:03.462034Z","iopub.execute_input":"2023-12-24T18:36:03.462496Z","iopub.status.idle":"2023-12-24T18:36:03.470319Z","shell.execute_reply.started":"2023-12-24T18:36:03.462457Z","shell.execute_reply":"2023-12-24T18:36:03.469391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src = \"https://awsmp-logos.s3.amazonaws.com/3426ff8f-c4da-4d6d-ae6c-46a02b4b0dc4/afbc6b177af177c2243749dfa88e0dec.png\" style =\"height:65%;width:65%;\">\n\n### I'll be utilizing W&B to monitor the model's performance.\n\nhttps://github.com/ultralytics/yolov5/issues/2362","metadata":{}},{"cell_type":"code","source":"# Weights & Biases (optional)\n%pip install -q wandb ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:31:14.408562Z","iopub.execute_input":"2023-12-24T18:31:14.408844Z","iopub.status.idle":"2023-12-24T18:31:28.202135Z","shell.execute_reply.started":"2023-12-24T18:31:14.40882Z","shell.execute_reply":"2023-12-24T18:31:28.200928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:31:28.203577Z","iopub.execute_input":"2023-12-24T18:31:28.203883Z","iopub.status.idle":"2023-12-24T18:31:37.611182Z","shell.execute_reply.started":"2023-12-24T18:31:28.203857Z","shell.execute_reply":"2023-12-24T18:31:37.61027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">READING THE DATA</p>","metadata":{}},{"cell_type":"code","source":"df_ess = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ndf_ess.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:05.732913Z","iopub.execute_input":"2023-12-24T18:36:05.733308Z","iopub.status.idle":"2023-12-24T18:36:05.883423Z","shell.execute_reply.started":"2023-12-24T18:36:05.733278Z","shell.execute_reply":"2023-12-24T18:36:05.882461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ess.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:05.976778Z","iopub.execute_input":"2023-12-24T18:36:05.977076Z","iopub.status.idle":"2023-12-24T18:36:06.015407Z","shell.execute_reply.started":"2023-12-24T18:36:05.977051Z","shell.execute_reply":"2023-12-24T18:36:06.014533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pro = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ndf_pro.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:06.10747Z","iopub.execute_input":"2023-12-24T18:36:06.107756Z","iopub.status.idle":"2023-12-24T18:36:06.123028Z","shell.execute_reply.started":"2023-12-24T18:36:06.107733Z","shell.execute_reply":"2023-12-24T18:36:06.122178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pro.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:06.309612Z","iopub.execute_input":"2023-12-24T18:36:06.309868Z","iopub.status.idle":"2023-12-24T18:36:06.319544Z","shell.execute_reply.started":"2023-12-24T18:36:06.309847Z","shell.execute_reply":"2023-12-24T18:36:06.31857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to @radek1 . Please upvote his dataset also - [LLM Generated Essays for the Detect AI Comp!](https://www.kaggle.com/datasets/radek1/llm-generated-essays)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n# External bir dataset oluÅŸturulmuÅŸ, bu import'lanÄ±yor.","metadata":{}},{"cell_type":"code","source":"## External Dataset\ndf_gpt_3_5 = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays.csv\")\ndf_gpt_4 = pd.read_csv(\"/kaggle/input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:07.298697Z","iopub.execute_input":"2023-12-24T18:36:07.299052Z","iopub.status.idle":"2023-12-24T18:36:07.384893Z","shell.execute_reply.started":"2023-12-24T18:36:07.299024Z","shell.execute_reply":"2023-12-24T18:36:07.384109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gpt_3_5.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:07.569549Z","iopub.execute_input":"2023-12-24T18:36:07.569849Z","iopub.status.idle":"2023-12-24T18:36:07.58008Z","shell.execute_reply.started":"2023-12-24T18:36:07.569824Z","shell.execute_reply":"2023-12-24T18:36:07.579284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_gpt_4.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:08.075041Z","iopub.execute_input":"2023-12-24T18:36:08.075392Z","iopub.status.idle":"2023-12-24T18:36:08.085635Z","shell.execute_reply.started":"2023-12-24T18:36:08.075364Z","shell.execute_reply":"2023-12-24T18:36:08.084671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### OluÅŸturulan external veri setiyle orijinal veri seti birleÅŸtirilir.","metadata":{}},{"cell_type":"code","source":"## Combining the original and external dataset\ndf_new = pd.concat([df_ess, df_gpt_3_5, df_gpt_4]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:08.666567Z","iopub.execute_input":"2023-12-24T18:36:08.667244Z","iopub.status.idle":"2023-12-24T18:36:08.679868Z","shell.execute_reply.started":"2023-12-24T18:36:08.667201Z","shell.execute_reply":"2023-12-24T18:36:08.678847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">EXPLORATORY DATA ANALYSIS</p>","metadata":{}},{"cell_type":"markdown","source":"### To begin, we'll initiate the exploration process exclusively on the **original dataset**.<br>\n## Distribution of Target Variable - Generated","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n   \n    \n### Generated deÄŸiÅŸkenine bakarak veri sayÄ±sÄ±nÄ± gÃ¶rselleÅŸtiriyoruz.","metadata":{}},{"cell_type":"code","source":"# Create a temporary dataframe with counts of each category\ncount_df = df_ess['generated'].value_counts().reset_index()\ncount_df.columns = ['generated', 'count']\n\nfig = px.bar(\n    count_df,\n    x='generated',\n    y='count',\n    title='Distribution of Generated Label',\n    color=['#2E86AB', '#E84545'],\n    color_discrete_map=\"identity\"\n)\n\n# Customize layout for value display\nfig.update_layout(\n    xaxis=dict(\n        tickmode='array',\n        tickvals=[0, 1])\n)\n\n# Display values on top of the bars\nfig.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside', \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:09.853176Z","iopub.execute_input":"2023-12-24T18:36:09.853616Z","iopub.status.idle":"2023-12-24T18:36:10.302223Z","shell.execute_reply.started":"2023-12-24T18:36:09.853583Z","shell.execute_reply":"2023-12-24T18:36:10.301265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The graph clearly shows that the dataset is highly imbalanced, with class 0 being the majority class.\n* There are a number of techniques that can be used to address class imbalance, such as upsampling and downsampling.\n* In this case, we will do upsampling and this is the reason we are using external dataset.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### Bulgular:\nVeri seti dengesiz, Ã¶ÄŸrenciler tarafÄ±ndan oluÅŸturulmuÅŸ makale sayÄ±sÄ± Ã¼stÃ¼nlÃ¼kte.\nBu dengesizliÄŸi dÃ¼zeltebilmek iÃ§in upsampling ve downsampling gibi teknikler kullanÄ±labilir. Bu Notebook'ta upsampling kullanÄ±lacak, bu yÃ¼zden external dataset'ini importladÄ±k.","metadata":{}},{"cell_type":"markdown","source":"## Exploration of Essay Text","metadata":{}},{"cell_type":"code","source":"df_ess['essay_len'] = df_ess['text'].str.split().map(lambda x : len(x))\n\nfig = px.histogram(\n    df_ess,\n    x='essay_len',\n    title='Distribution of word count of text',\n    color_discrete_sequence=['#FF7F0E'], \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:11.366Z","iopub.execute_input":"2023-12-24T18:36:11.366866Z","iopub.status.idle":"2023-12-24T18:36:11.558726Z","shell.execute_reply.started":"2023-12-24T18:36:11.366834Z","shell.execute_reply":"2023-12-24T18:36:11.557852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The histogram shows that mostly essay has around 500-600 words.\n* It also displays some outliers, with a few essays exceeding 1200 words.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n# Bulgular\nÃ‡oÄŸu makale 500-600 kelimeye sahip. BirkaÃ§ tane aykÄ±rÄ± deÄŸer bulunuyor (1200 kelimelik makaleler)","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(\n    df_ess,\n    x='essay_len',\n    title='Word Count Distribution Across Prompts',\n    color=\"prompt_id\",\n    color_discrete_sequence=px.colors.qualitative.Bold,\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:12.73616Z","iopub.execute_input":"2023-12-24T18:36:12.736546Z","iopub.status.idle":"2023-12-24T18:36:12.816107Z","shell.execute_reply.started":"2023-12-24T18:36:12.736516Z","shell.execute_reply":"2023-12-24T18:36:12.815215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* This shows that the essays proposed by prompt id 0 are generally longer than the essays proposed by prompt id 1.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n   \n   \n    \n# Bulgular\n0.prompt_id'ye karÅŸÄ±lÄ±k olarak yazÄ±lmÄ±ÅŸ makaleler genel olarak, 1. prompt id'ye karÅŸÄ±lÄ±k olarak yazÄ±lmÄ±ÅŸ makalelerden daha uzun.","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:35:14.032513Z","iopub.execute_input":"2023-12-24T18:35:14.032924Z","iopub.status.idle":"2023-12-24T18:35:14.040482Z","shell.execute_reply.started":"2023-12-24T18:35:14.032893Z","shell.execute_reply":"2023-12-24T18:35:14.039226Z"}}},{"cell_type":"markdown","source":"### After conducting preliminary exploration, we will now delve into our **updated dataset**, which incorporates an **external dataset**. This adjustment is necessary since the original dataset is highly biased, making it unsuitable for effective model generation.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of Target Variable - Generated","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n    \n    \n#### Kodun devamÄ±nda, external dataset dahil edilmiÅŸ olan gÃ¼ncel veri seti kullanÄ±lacak. Bu ÅŸekilde daha dengeli bir veri seti olacak.","metadata":{}},{"cell_type":"code","source":"# Create a temporary dataframe with counts of each category\ncount_df = df_new['generated'].value_counts().reset_index()\ncount_df.columns = ['generated', 'count']\n\nfig = px.bar(\n    count_df,\n    x='generated',\n    y='count',\n    title='Distribution of Generated Label',\n    color=['#FECB52', '#FF97FF'],\n    color_discrete_map=\"identity\"\n)\n\n# Customize layout for value display\nfig.update_layout(\n    xaxis=dict(\n        tickmode='array',\n        tickvals=[0, 1])\n)\n\n# Display values on top of the bars\nfig.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside', \n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:36:14.579869Z","iopub.execute_input":"2023-12-24T18:36:14.580599Z","iopub.status.idle":"2023-12-24T18:36:14.656698Z","shell.execute_reply.started":"2023-12-24T18:36:14.580564Z","shell.execute_reply":"2023-12-24T18:36:14.655713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The dataset is now have been more balanced by upsampling the data.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of Prompt ID","metadata":{}},{"cell_type":"code","source":"fig_hist = px.histogram(\n    df_new,\n    x='prompt_id',\n    title='Prompt ID Distribution by Generated Category',\n    color='generated',\n    barmode='group',\n    color_discrete_sequence=px.colors.qualitative.D3[3:],\n)\n\n# Display values on top of the bars\nfig_hist.update_traces(\n    texttemplate='%{y}',  \n    textposition='outside',  \n)\n\nfig_hist.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:37:22.556759Z","iopub.execute_input":"2023-12-24T18:37:22.557444Z","iopub.status.idle":"2023-12-24T18:37:22.636638Z","shell.execute_reply.started":"2023-12-24T18:37:22.557413Z","shell.execute_reply":"2023-12-24T18:37:22.63555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The graph shows that the distribution of the both the prompts is almost similar.\n* We have more essays written by student for both the prompts which is expected also.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n## Prompt'lar hemen hemen eÅŸit daÄŸÄ±tÄ±lmÄ±ÅŸ. ","metadata":{}},{"cell_type":"markdown","source":"## Exploration of Essay Text","metadata":{}},{"cell_type":"code","source":"df_new['essay_len'] = df_new['text'].str.split().map(lambda x : len(x))\ndf_llm = df_new[df_new[\"generated\"]==1]\n\nfig = px.histogram(\n    df_llm,\n    x='essay_len',\n    title='Distribution of word count of text generated by LLM',\n    color_discrete_sequence=['#73AF48']\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:38:11.062019Z","iopub.execute_input":"2023-12-24T18:38:11.062838Z","iopub.status.idle":"2023-12-24T18:38:11.252724Z","shell.execute_reply.started":"2023-12-24T18:38:11.062804Z","shell.execute_reply":"2023-12-24T18:38:11.251726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INSIGHTS\n\n* The distribution is not perfectly normal, as there is a slight skew to the right. This means that there are more essays with a higher number of words than essays with a lower number of words.\n* The majority of essays have a word count between 400-600 words.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n## DaÄŸÄ±lma standard bir daÄŸÄ±lÄ±m deÄŸil, saÄŸa doÄŸru biraz kayma var. Genelde makaleler 400-600 kelime aralÄ±ÄŸÄ±nda.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(\n    df_new,\n    x='essay_len',\n    title='Distribution of word count of text grouped by prompt_id ',\n    color=\"prompt_id\",\n    color_discrete_sequence=px.colors.qualitative.Safe,\n    barmode=\"group\",\n)\n\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:39:03.790364Z","iopub.execute_input":"2023-12-24T18:39:03.790735Z","iopub.status.idle":"2023-12-24T18:39:03.856419Z","shell.execute_reply.started":"2023-12-24T18:39:03.790704Z","shell.execute_reply":"2023-12-24T18:39:03.855572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The distribution of word count for prompt id 0 is more skewed to the right than the distribution of word count for prompt id 1. This suggests that there are more essays generated by prompt id 0 with a very high number of words.\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n### Prompt_id 0'a karÅŸÄ±lÄ±k yazÄ±lmÄ±ÅŸ makalelerin kaymasÄ± daha saÄŸa doÄŸru fakat prompt_id 1'e karÅŸÄ±lÄ±k yazÄ±lmÄ±ÅŸ makalelerin kaymasÄ± daha sola doÄŸru. Bu demek oluyor ki, prompt_id 0'a karÅŸÄ±lÄ±k yazÄ±lmÄ±ÅŸ makaleler daha fazla kelime iÃ§eriyor.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n    \n# AÅŸaÄŸÄ±daki kodda en sÄ±k kullanÄ±lmÄ±ÅŸ kelimeler, sÄ±rayla Ã¶ÄŸrenciler ve LLM tarafÄ±ndan yazÄ±lmÄ±ÅŸ makalelere gÃ¶re dÃ¼zenlenmiÅŸ.\n    \nÄ°lk baÅŸta stopwords dahil edilmiÅŸ sÄ±ralamaya (the, on, off vb. kelimeler). SonrasÄ±nda dahil edilmeden tekrar hesaplanmÄ±ÅŸ.","metadata":{}},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_ess['text'] for word in words.split()])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (including stopwords) in Essays Written by Students', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Vivid)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:40:19.360737Z","iopub.execute_input":"2023-12-24T18:40:19.361162Z","iopub.status.idle":"2023-12-24T18:40:19.716165Z","shell.execute_reply.started":"2023-12-24T18:40:19.361131Z","shell.execute_reply":"2023-12-24T18:40:19.715206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_ess['text'] for word in words.split() if word.lower() not in set(stopwords.words(\"english\"))])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (excluding stopwords) in Essays Written by Students', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Vivid)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:40:24.165385Z","iopub.execute_input":"2023-12-24T18:40:24.165757Z","iopub.status.idle":"2023-12-24T18:41:59.902708Z","shell.execute_reply.started":"2023-12-24T18:40:24.165728Z","shell.execute_reply":"2023-12-24T18:41:59.901782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_llm['text'] for word in words.split()])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (including stopwords) in Essays Generated by LLMs', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Set1)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:43:23.077109Z","iopub.execute_input":"2023-12-24T18:43:23.078015Z","iopub.status.idle":"2023-12-24T18:43:23.298897Z","shell.execute_reply.started":"2023-12-24T18:43:23.07798Z","shell.execute_reply":"2023-12-24T18:43:23.297934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_occ = Counter([word.lower() for words in df_llm['text'] for word in words.split() if word.lower() not in set(stopwords.words(\"english\"))])\ndf_temp = pd.DataFrame(word_occ.most_common(10))\ndf_temp.columns = ['Common Words','count']\n\nfig = px.bar(df_temp, \n             x='count', \n             y='Common Words', \n             title='Most Common Words (excluding stopwords) in Essays Generated by LLMs', \n             orientation='h', \n             width=900,\n             height=700, \n             color='Common Words',\n            color_discrete_sequence=px.colors.qualitative.Set1)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:43:23.343209Z","iopub.execute_input":"2023-12-24T18:43:23.34353Z","iopub.status.idle":"2023-12-24T18:44:08.959035Z","shell.execute_reply.started":"2023-12-24T18:43:23.343506Z","shell.execute_reply":"2023-12-24T18:44:08.95808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## INSIGHTS\n* The above plots reveal differences in common words between essays written by students and those generated by LLMs. \n* This observation implies that such differences could be valuable for classifying essays.","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n### SÄ±k kullanÄ±lan kelimeler arasÄ±nda LLM veya Ã¶ÄŸrenci tarafÄ±ndan yazÄ±lmÄ±ÅŸ olmasÄ±nÄ±n verdiÄŸi bir fark var. Bu, sÄ±nÄ±flandÄ±rma iÅŸleminde kullanÄ±labilir.","metadata":{}},{"cell_type":"markdown","source":"## WordCloud","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n### Kelime bulutu oluÅŸturulur. En sÄ±k kullanÄ±lan kelimelerin, toplu bir ÅŸekilde gÃ¶rselleÅŸtirilmesini saÄŸlar.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\n\ntext = df_new['text'].values\nurl = 'https://www.llmsolicitors.co.uk/wp-content/themes/llmsolicitors/image/avatar.png'\nimg = np.array(Image.open(requests.get(url, stream=True).raw))\n\n# Center cropping\nwidth, height = img.shape[1], img.shape[0]\nmid_x, mid_y = int(width/2), int(height/2)\ncw2, ch2 = int(width/4), int(height/4) \ncrop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]\n\ncloud = WordCloud(stopwords = STOPWORDS,\n                  background_color='white',\n                  min_font_size=3,\n                  mask = crop_img,\n                  max_words = 500,\n                  colormap='Dark2'\n                  ).generate(\" \".join(text))\n\nplt.imshow(cloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:44:12.018366Z","iopub.execute_input":"2023-12-24T18:44:12.018728Z","iopub.status.idle":"2023-12-24T18:44:17.41087Z","shell.execute_reply.started":"2023-12-24T18:44:12.018701Z","shell.execute_reply":"2023-12-24T18:44:17.40987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">CREATE FOLDS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n# Veri setini, Ã§apraz doÄŸrulama yapma amacÄ±yla bÃ¶lmek iÃ§in stratified k-fold iÅŸlemi uygulanÄ±yor. Stratified K-Fold, her katlamada hedef deÄŸiÅŸkenin sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n orijinal veri seti ile aynÄ± olmasÄ±nÄ± saÄŸlar. Bu, Ã¶zellikle sÄ±nÄ±f dengesizliÄŸinin olduÄŸu durumlarda Ã¶nemlidir. Overfitting'i Ã¶nlemek iÃ§in yapÄ±lÄ±r.","metadata":{}},{"cell_type":"code","source":"# Use Stratified K-Fold for cross-validation\nskf = StratifiedKFold(n_splits=CONFIG.num_fold, shuffle=True, random_state=CONFIG.seed)\n\n# Assign folds to the dataframe\nfor k, (_, val_ind) in enumerate(skf.split(X=df_new, y=df_new['generated'])):\n    df_new.loc[val_ind, 'fold'] = k","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:45:03.805525Z","iopub.execute_input":"2023-12-24T18:45:03.805919Z","iopub.status.idle":"2023-12-24T18:45:03.820207Z","shell.execute_reply.started":"2023-12-24T18:45:03.805886Z","shell.execute_reply":"2023-12-24T18:45:03.819302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">DATASET CLASS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n    \n\n## LLMTextData denilen Ã¶zel bir sÄ±nÄ±f oluÅŸturulur. \n#### \\_ \\_len_ \\_(self): Veri setindeki Ã¶rnek sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.\n#### \\_ \\_getitem_ \\_: Verilen bir index iÃ§in veri setinden bir Ã¶rnek (makale ve prompt) alÄ±r.","metadata":{}},{"cell_type":"code","source":"class LLMTextData(Dataset):\n    def __init__(self, df):\n        self.text = df['text']\n        self.generated = df['generated']\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        generated = self.generated[index]\n        \n        inputs = CONFIG.tokenizer(text, padding='max_length', max_length=CONFIG.max_len, truncation=True)\n        \n        input_ids = inputs[\"input_ids\"]\n        attention_mask = inputs[\"attention_mask\"]\n        \n        return {\n            \"ids\": torch.tensor(input_ids, dtype=torch.long),\n            \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n            \"label\": torch.tensor(generated, dtype=torch.int),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-24T18:51:23.296014Z","iopub.execute_input":"2023-12-24T18:51:23.296777Z","iopub.status.idle":"2023-12-24T18:51:23.304517Z","shell.execute_reply.started":"2023-12-24T18:51:23.296742Z","shell.execute_reply":"2023-12-24T18:51:23.303564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">BASELINE MODEL</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n    \n#### AÅŸaÄŸÄ±daki kod, makine Ã¶ÄŸrenme model sÄ±nÄ±fÄ± oluÅŸturur. Metin verileri Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in tasarlanmÄ±ÅŸtÄ±r ve RoBERTa modelini kullanÄ±r (bir transformers modelidir).\n## LLMDetectModel SÄ±nÄ±fÄ±\n\n## 1. _ \\_init_ \\_\n\nKullanÄ±lacak modelin adÄ±, modelin path'ini ve pretrained olup olmadÄ±ÄŸÄ± bilgilerini alÄ±r. EÄŸer pretrained deÄŸilse, config deÄŸerlerinden konfigÃ¼rasyonu alarak modeli eÄŸitir.\n \n## 2. _ \\_forward_ \\_ \nModelin nasÄ±l tahminler yapacaÄŸÄ±nÄ± tanÄ±mlar. Veriler Ã¶nce RoBERTa modeline yollanÄ±r, ardÄ±ndan CNN teknikleri kullanÄ±larak sonuÃ§ elde edilir.\n    \n    \nSÄ±nÄ±f, RoBERTa sinir aÄŸÄ±nÄ±  kullanarak metin verileri Ã¼zerinde tahminler yapmak iÃ§in tasarlanmÄ±ÅŸtÄ±r. SÄ±nÄ±f, modelin yapÄ±landÄ±rmasÄ±nÄ± yÃ¼klemek, gerektiÄŸinde Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± kullanmak ve ek katmanlar eklemek iÃ§in kullanÄ±lÄ±r.\n    ","metadata":{}},{"cell_type":"code","source":"class LLMDetectModel(nn.Module):\n    def __init__(self, model_name, model_path=None, pretrained=True):\n        super(LLMDetectModel, self).__init__()\n        \n        if model_path is None:\n            self.config = AutoConfig.from_pretrained(model_name)\n            self.config.update({\"output_hidden_states\":True, \n                           \"hidden_dropout_prob\": 0.0,\n                           \"layer_norm_eps\": 1e-7})\n        else:\n            self.config = torch.load(model_path+\"/config.pth\")\n        \n        if pretrained:\n            self.roberta = AutoModel.from_pretrained(model_name, config=self.config)\n        else:\n            self.roberta = AutoModel.from_config(self.config)\n            \n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.linear = nn.Linear(self.config.hidden_size,1)\n        \n    def forward(self, input_ids, attention_mask=None):\n        x = self.roberta(input_ids, attention_mask)[0]\n        x = self.pool(x.permute(0, 2, 1)).view(x.size(0), -1)\n        x = self.linear(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.751989Z","iopub.execute_input":"2023-12-04T11:49:25.752342Z","iopub.status.idle":"2023-12-04T11:49:25.761972Z","shell.execute_reply.started":"2023-12-04T11:49:25.752309Z","shell.execute_reply":"2023-12-04T11:49:25.761119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n\n# <p style=\"background-color:#C1FFC1;font-family:cursive;color:#A0522D;font-size:150%;text-align:center;border-radius:10px 10px;line-height:1.5\">UTILITY FUNCTIONS</p>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n\n### Veri YÃ¼kleyicileri (Data Loaders)\n    \n#### 1. get_data(fold): \n#### Train ve validation data loader'larÄ±nÄ± al\n<hr>\n\n#### 2. loss_fn \n#### Modelin Ã§Ä±ktÄ±larÄ± ile gerÃ§ek etiketler arasÄ±ndaki uyumsuzluÄŸu hesaplar.\n<hr>\n\n#### 3. calculate_roc_auc \n#### ROC-AUC skoru hesaplar\n<hr>\n\n#### 4. get_optimizer\n#### Model parametrelerini optimize etmek iÃ§in kullanÄ±lan yÃ¶ntemdir. Bu kodda AdamW optimizasyon algoritmasÄ± kullanÄ±lÄ±yor.\n<hr>\n\n#### 5. get_scheduler\n#### lineer veya kosinÃ¼s zamanlamasÄ±: Ã–ÄŸrenme oranÄ±nÄ± belirli bir stratejiye gÃ¶re azaltÄ±r. Modelin eÄŸitim sÃ¼recinde daha hÄ±zlÄ± ilerlemesini ve son aÅŸamada daha hassas ayar yapmasÄ±nÄ± saÄŸlar.\n<hr>\n\nGenel AmaÃ§\n\n.1. **Veri HazÄ±rlama:** \n    \n.2. **KayÄ±p Fonksiyonu:** Modelin performansÄ±nÄ± Ã¶lÃ§mek ve iyileÅŸtirmek iÃ§in kullanÄ±lan bir fonksiyondur.\n    \n.3. **Performans MetriÄŸi:** Modelin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan metrik.\n    \n.4. **Optimizasyon ve Zamanlama:** Modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemek iÃ§in kullanÄ±lÄ±r.\n\n","metadata":{}},{"cell_type":"code","source":"# Function to get training and validation data loaders for a given fold\ndef get_data(fold):\n    train_df = df_new[df_new['fold'] != fold].reset_index(drop=True)\n    valid_df = df_new[df_new['fold'] == fold].reset_index(drop=True)\n    \n    train_dataset = LLMTextData(train_df)\n    valid_dataset = LLMTextData(valid_df)\n    \n    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch_size, shuffle=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch_size, shuffle=True)\n    \n    return train_loader, valid_loader\n\n# Loss function definition\ndef loss_fn(outputs, labels):\n    return nn.BCEWithLogitsLoss()(outputs, labels)\n\n# Function to calculate ROC-AUC score\ndef calculate_roc_auc(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n# Function to get the optimizer\ndef get_optimizer(model):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {\n            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.01\n        },\n        {\n            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0\n        },\n    ]\n\n    optimizer = AdamW(optimizer_parameters, lr=CONFIG.learning_rate)\n\n    return optimizer\n\n# Function to get learning rate scheduler based on the specified type in CONFIG\ndef get_scheduler(cfg, optimizer, train_loader):\n    if cfg.scheduler == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int((len(train_loader)*CONFIG.epochs*6)/100),\n            num_training_steps=CONFIG.epochs*len(train_loader),\n        )\n    elif cfg.scheduler == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=int((len(train_loader)*CONFIG.epochs*6)/100),\n            num_training_steps=CONFIG.epochs*len(train_loader),\n        )\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.76344Z","iopub.execute_input":"2023-12-04T11:49:25.76385Z","iopub.status.idle":"2023-12-04T11:49:25.778948Z","shell.execute_reply.started":"2023-12-04T11:49:25.763819Z","shell.execute_reply":"2023-12-04T11:49:25.778204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:center;\n           padding: 10px 10px\">\n\n#### AÅŸaÄŸÄ±daki iki fonksiyon, modelin nasÄ±l eÄŸitileceÄŸini ve nasÄ±l deÄŸerlendirileceÄŸini gÃ¶sterir. (train_fn), modeli gerÃ§ek etiketlerle eÄŸitir. (valid_fn), modelin eÄŸitim sÄ±rasÄ±nda nasÄ±l performans gÃ¶sterdiÄŸini deÄŸerlendirir.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"# Function to train the model\ndef train_fn(model, data_loader, optimizer, scheduler, device, epoch):\n    # Set the model to training mode\n    model.train()\n    \n    running_loss = 0\n    progress_bar = tqdm(data_loader, position=0)\n    preds = []\n    label = []\n    \n    for step, data in enumerate(progress_bar):\n        # Move data to the specified device\n        ids = data['ids'].to(device)\n        masks = data['mask'].to(device)\n        labels = data['label'].to(device, dtype = torch.float)\n        \n        # Forward pass\n        outputs = model(ids, masks)\n        \n        # Compute the loss\n        loss = loss_fn(outputs, labels.unsqueeze(1))\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        # Adjust learning rate if a scheduler is provided\n        if scheduler is not None:\n            scheduler.step()\n        \n        running_loss += loss.item()\n        \n        # Collect predictions and labels for later evaluation\n        preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        # Update progress bar\n        progress_bar.set_description(f\"Epoch [{epoch+1}/{CONFIG.epochs}]\")\n        progress_bar.set_postfix(loss=running_loss/(step+1))\n        \n        # Log the loss\n        wandb.log({\"Train Loss\": running_loss/(step+1)})\n    \n    # Calculate ROC-AUC on the training set\n    train_auc = calculate_roc_auc(np.array(label), np.array(preds))\n    \n    return train_auc\n        \n# Function to validate the model        \ndef valid_fn(model, data_loader, device, epoch):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    running_loss = 0\n    progress_bar = tqdm(data_loader, position=0)\n    preds = []\n    label = []\n    \n    with torch.no_grad():\n        \n        for step, data in enumerate(progress_bar):\n            # Move data to the specified device\n            ids = data['ids'].to(device)\n            masks = data['mask'].to(device)\n            labels = data['label'].to(device, dtype = torch.float)\n            \n            # Forward pass\n            outputs = model(ids, masks)\n            \n            # Compute the loss\n            loss = loss_fn(outputs, labels.unsqueeze(1))\n\n            running_loss += loss.item()\n            \n            # Collect predictions and labels for later evaluation\n            preds.extend(torch.sigmoid(outputs).view(-1).cpu().detach().numpy())\n            label.extend(labels.view(-1).cpu().detach().numpy())\n            \n            # Update progress bar\n            progress_bar.set_description(f\"Epoch [{epoch+1}/{CONFIG.epochs}]\")\n            progress_bar.set_postfix(loss=running_loss/(step+1))\n            \n            # Log the loss\n            wandb.log({\"Valid Loss\": running_loss/(step+1)})\n        \n        # Calculate ROC-AUC on the validation set\n        valid_auc = calculate_roc_auc(np.array(label), np.array(preds))\n    \n    return valid_auc         ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:49:25.780198Z","iopub.execute_input":"2023-12-04T11:49:25.78048Z","iopub.status.idle":"2023-12-04T11:49:25.797471Z","shell.execute_reply.started":"2023-12-04T11:49:25.780458Z","shell.execute_reply":"2023-12-04T11:49:25.796612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:20px;\n           background-color:#4b7068;\n           font-size:120%;\n           font-family: Lucida Console, Courie;\n           letter-spacing:0.5px;\n           text-align:;\n           padding: 10px 20px\">\n\n* run fonksiyonu, modelin eÄŸitim ve doÄŸrulama sÃ¼reÃ§lerini yÃ¶netir ve modelin performansÄ±nÄ± deÄŸerlendirir.\n    \n    \nModelin veri Ã¼zerinde ne kadar iyi Ã¶ÄŸrendiÄŸini anlamak iÃ§in ROC-AUC skorlarÄ± kullanÄ±r.\nEÄŸitim sÃ¼resince modelin en iyi performans gÃ¶sterdiÄŸi anÄ±n aÄŸÄ±rlÄ±klarÄ± kaydedilir, bÃ¶ylece model daha sonra bu en iyi durumuyla kullanÄ±labilir.","metadata":{}},{"cell_type":"code","source":"# Function to execute the training and validation process for a specific fold.\ndef run(fold):\n    # Get data loaders for the specified fold\n    train_loader, valid_loader = get_data(fold)\n    \n    # Instantiate the LLMDetectModel and move it to the specified device\n    model = LLMDetectModel(CONFIG.model).to(CONFIG.device)\n    \n    if not os.path.exists(\"./config.pth\"):\n        torch.save(model.config,\"./config.pth\")\n    \n    # Get the optimizer for the model\n    optimizer = get_optimizer(model)\n    \n    # Get the learning rate scheduler based on the specified configuration\n    scheduler = get_scheduler(CONFIG, optimizer, train_loader)\n    \n    # Initialize the best validation ROC-AUC score\n    best_valid_auc = 0\n        \n    # Training loop for the specified number of epochs\n    for epoch in range(CONFIG.epochs):\n        train_auc = train_fn(model, train_loader, optimizer, scheduler, CONFIG.device, epoch)\n        valid_auc = valid_fn(model, valid_loader, CONFIG.device, epoch)\n        print(f\"Train ROC AUC - {train_auc}, Valid ROC AUC - {valid_auc}\")\n        \n        # Log the metrics\n        wandb.log({\"Train AUC\": train_auc})\n        wandb.log({\"Valid AUC\": valid_auc})\n        \n        # Check if the validation ROC-AUC has improved, and if so, save the model checkpoint\n        if valid_auc > best_valid_auc:\n            print(f\"Validation ROC AUC Improved - {best_valid_auc} ---> {valid_auc}\")\n            torch.save(model.state_dict(), f'./model_{fold}.bin')\n            print(f\"Saved model checkpoint at ./model_{fold}.bin\")\n            best_valid_auc = valid_auc\n    \n    return best_valid_auc","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:52:03.893863Z","iopub.execute_input":"2023-12-04T11:52:03.894201Z","iopub.status.idle":"2023-12-04T11:52:03.903498Z","shell.execute_reply.started":"2023-12-04T11:52:03.894176Z","shell.execute_reply":"2023-12-04T11:52:03.902487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main loop for training on all folds\nfor fold in range(CONFIG.num_fold):\n    print(\"=\" * 30)\n    print(\"Training Fold - \", fold)\n    print(\"=\" * 30)\n    \n    wandb_run = wandb.init(project='Detect Authors', \n                     group=f\"Fold - {fold}\"\n                     )\n    \n    best_valid_auc = run(fold)\n    print(f'Best ROC AUC: {best_valid_auc:.5f}')\n    \n    wandb_run.finish()\n    \n    gc.collect()\n    torch.cuda.empty_cache()    ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T11:52:53.32311Z","iopub.execute_input":"2023-12-04T11:52:53.32347Z","iopub.status.idle":"2023-12-04T11:53:00.148956Z","shell.execute_reply.started":"2023-12-04T11:52:53.323442Z","shell.execute_reply":"2023-12-04T11:53:00.147596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [Click here to view the entire dashboard](https://wandb.ai/utcarshagrawal/Detect%20Authors)\n<img src=\"https://i.imgur.com/dTVNOnR.png\">","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n    <h2 align='center'>THANK YOU!!</h2>\n    <h3 align='center'>Please do an upvote if you found the notebook useful.</h3>\n</div>","metadata":{}}]}